{"cells":[{"cell_type":"markdown","source":["# Federated learning with YOLOv8"],"metadata":{"id":"dd6FmFRMZZ-Z"}},{"cell_type":"markdown","source":["## Before you start"],"metadata":{"id":"vMMKHSCqagiF"}},{"cell_type":"markdown","source":["Let's make sure that you have access to a GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Runtime` -> `Change Runtime Type` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`."],"metadata":{"id":"UWA2pQpZatV5"}},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"K0Zw7t7_bAu_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1721234771216,"user_tz":-120,"elapsed":381,"user":{"displayName":"Lorenzo Sorrentino","userId":"10740165800852379071"}},"outputId":"dd121156-7cf4-4f06-8d47-d4f6f012462e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Jul 17 16:46:08 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   41C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","source":["## Install the ultralytics library"],"metadata":{"id":"v426nVn9Zv8y"}},{"cell_type":"code","source":["!pip install ultralytics"],"metadata":{"id":"6YMVo3i5ZuNT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Download the datasets"],"metadata":{"id":"xuka0kaSdQez"}},{"cell_type":"markdown","source":["Download the datasets from GitHub"],"metadata":{"id":"-XqKaSrOTQrO"}},{"cell_type":"code","source":["%cd /content\n","!git clone https://github.com/losor2002/FederatedLearningYOLOv8.git\n","!mv FederatedLearningYOLOv8/datasets .\n","!rm -r FederatedLearningYOLOv8"],"metadata":{"id":"wLKifmFfTSr0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Train the model"],"metadata":{"id":"M1lkSc4CJAiW"}},{"cell_type":"markdown","source":["Configure the run and train the model"],"metadata":{"id":"wxitpunq-8Nx"}},{"cell_type":"code","source":["%cd /content\n","\n","from ultralytics import YOLO\n","import copy\n","import torch\n","from numpy import random\n","import os\n","\n","# Configure the run\n","PROJECT = 'test'\n","DATASET = 'augmented1000'\n","GLOBAL_MODEL_EPOCHS = 5\n","FEDERATED = False\n","GLOBAL_FEDERATED_EPOCHS = 5\n","CLIENT_EPOCHS = 20\n","TOTAL_FEDERATED_CLIENTS = 5\n","ACTIVE_FEDERATED_CLIENTS = 3\n","BEST_MAPS = 3\n","GLOBAL_AVG_EPOCHS = 1\n","\n","# Define the averaging function\n","def average_weights(w):\n","  w_avg = copy.deepcopy(w[0])\n","  for key in w_avg.keys():\n","      for i in range(1, len(w)):\n","          w_avg[key] += w[i][key]\n","      w_avg[key] = torch.div(w_avg[key], len(w))\n","  return w_avg\n","\n","def main():\n","  # Check if the project already exists\n","  if os.path.exists('/content/runs/' + PROJECT):\n","    raise Exception(f'Project {PROJECT} already exists, choose a new project name')\n","\n","  # Print the run configuration\n","  print('PROJECT : ' + PROJECT)\n","  print('DATASET : ' + DATASET)\n","  print('GLOBAL_MODEL_EPOCHS : ' + str(GLOBAL_MODEL_EPOCHS))\n","  print('FEDERATED : ' + str(FEDERATED))\n","  print('GLOBAL_FEDERATED_EPOCHS : ' + str(GLOBAL_FEDERATED_EPOCHS))\n","  print('CLIENT_EPOCHS : ' + str(CLIENT_EPOCHS))\n","  print('TOTAL_FEDERATED_CLIENTS : ' + str(TOTAL_FEDERATED_CLIENTS))\n","  print('ACTIVE_FEDERATED_CLIENTS : ' + str(ACTIVE_FEDERATED_CLIENTS))\n","  print('BEST_MAPS : ' + str(BEST_MAPS))\n","  print('GLOBAL_AVG_EPOCHS : ' + str(GLOBAL_AVG_EPOCHS))\n","\n","  # Initialize the global model YOLOv8 for object detection\n","  global_model = YOLO('yolov8n.pt')\n","\n","  # Train the global model\n","  results = global_model.train(data=f'datasets/{DATASET}/global/data.yaml',\n","                               epochs=GLOBAL_MODEL_EPOCHS, name='global0',\n","                               project=f'runs/{PROJECT}')\n","\n","  # Print the mAP\n","  print('global0 mAP = ' + str(results.box.map))\n","\n","  if not FEDERATED:\n","    return\n","\n","  # Initialize the random number generator\n","  rng = random.default_rng()\n","\n","  #Start the federated learning\n","  for epoch in range(1, GLOBAL_FEDERATED_EPOCHS + 1):\n","    print(f'\\n | Global Training Round : {epoch} |\\n')\n","\n","    # Array of tuples (client, client mAP)\n","    maps = []\n","\n","    # Select the clients\n","    clients = rng.choice(TOTAL_FEDERATED_CLIENTS, ACTIVE_FEDERATED_CLIENTS,\n","                         replace=False)\n","    clients.sort()\n","    print('Clients : ' + str(clients))\n","\n","    # Train the clients\n","    for client in clients:\n","      # Set up the client model\n","      client_model = YOLO(f'runs/{PROJECT}/global{epoch - 1}/weights/best.pt')\n","\n","      # Train the client model\n","      client_res = client_model.train(data=f'datasets/{DATASET}/client{client}/data.yaml',\n","                                      epochs=CLIENT_EPOCHS, name=f'client{epoch}{client}',\n","                                      project=f'runs/{PROJECT}')\n","\n","      # Print the client mAP\n","      print(f'client{epoch}{client} mAP = ' + str(client_res.box.map))\n","\n","      # Save the mAP\n","      maps.append((client, client_res.box.map))\n","\n","    clients_weights = []\n","\n","    # Sort by mAP and take the n best\n","    maps.sort(key=lambda tup: tup[1], reverse=True)\n","    for i in range(BEST_MAPS):\n","      client_model = YOLO(f'runs/{PROJECT}/client{epoch}{maps[i][0]}/weights/best.pt')\n","      clients_weights.append(client_model.state_dict())\n","      print(f'chosen client{epoch}{maps[i][0]} mAP = ' + str(maps[i][1]))\n","\n","    # Average clients best weights\n","    avg_weights = average_weights(clients_weights)\n","\n","    #Load the global model and train to test and save the average weights\n","    global_model = YOLO(f'runs/{PROJECT}/global{epoch - 1}/weights/best.pt')\n","    global_model.load_state_dict(avg_weights)\n","    results = global_model.train(data=f'datasets/{DATASET}/global/data.yaml',\n","                                 epochs=GLOBAL_AVG_EPOCHS, name=f'global{epoch}',\n","                                 project=f'runs/{PROJECT}')\n","    print('global' + str(epoch) + ' mAP = ' + str(results.box.map))\n","\n","try:\n","  main()\n","finally:\n","  # Restart the runtime to clean the memory\n","  exit()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uAHWKKlW--WT","outputId":"d0f78d37-78fd-439e-81f5-556a7589940a","executionInfo":{"status":"ok","timestamp":1721235248598,"user_tz":-120,"elapsed":173700,"user":{"displayName":"Lorenzo Sorrentino","userId":"10740165800852379071"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","PROJECT : test\n","DATASET : augmented1000\n","GLOBAL_MODEL_EPOCHS : 5\n","FEDERATED : False\n","GLOBAL_FEDERATED_EPOCHS : 5\n","CLIENT_EPOCHS : 20\n","TOTAL_FEDERATED_CLIENTS : 5\n","ACTIVE_FEDERATED_CLIENTS : 3\n","BEST_MAPS : 3\n","GLOBAL_AVG_EPOCHS : 1\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.25M/6.25M [00:00<00:00, 168MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.2.58 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=datasets/augmented1000/global/data.yaml, epochs=5, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=runs/test, name=global0, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/test/global0\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 42.0MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Overriding model.yaml nc=80 with nc=1\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n","Model summary: 225 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n","\n","Transferred 319/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/test/global0', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/augmented1000/global/train/labels... 800 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 800/800 [00:00<00:00, 1835.13it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/augmented1000/global/train/labels.cache\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/augmented1000/global/valid/labels... 200 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:00<00:00, 665.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/augmented1000/global/valid/labels.cache\n","Plotting labels to runs/test/global0/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/test/global0\u001b[0m\n","Starting training for 5 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        1/5      2.59G      1.635      2.588      1.563         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:25<00:00,  1.97it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:06<00:00,  1.06it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        200        503      0.886      0.093      0.333      0.168\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        2/5      2.17G      1.525       1.93      1.463         53        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:19<00:00,  2.51it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  2.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all        200        503      0.461      0.352      0.357      0.182\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        3/5      2.29G      1.516      1.786      1.449        100        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:19<00:00,  2.60it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  2.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all        200        503      0.477      0.499      0.461      0.236\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        4/5      2.29G      1.465      1.675      1.407         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:21<00:00,  2.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  2.36it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        200        503      0.652      0.497      0.573      0.329\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["        5/5      2.17G      1.378      1.507      1.352         57        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:19<00:00,  2.56it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:04<00:00,  1.72it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all        200        503      0.703      0.674      0.726      0.442\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","5 epochs completed in 0.037 hours.\n","Optimizer stripped from runs/test/global0/weights/last.pt, 6.2MB\n","Optimizer stripped from runs/test/global0/weights/best.pt, 6.2MB\n","\n","Validating runs/test/global0/weights/best.pt...\n","Ultralytics YOLOv8.2.58 ðŸš€ Python-3.10.12 torch-2.3.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 168 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:05<00:00,  1.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all        200        503      0.703      0.674      0.726      0.442\n","Speed: 0.2ms preprocess, 3.7ms inference, 0.0ms loss, 6.2ms postprocess per image\n","Results saved to \u001b[1mruns/test/global0\u001b[0m\n","global0 mAP = 0.44167053836123393\n"]}]},{"cell_type":"markdown","source":["## Clean the runtime"],"metadata":{"id":"YMWAtZwBYJkk"}},{"cell_type":"markdown","source":["Use this to restart the runtime and clean the memory if needed"],"metadata":{"id":"rBqPEYROYOAO"}},{"cell_type":"code","source":["exit()"],"metadata":{"id":"-hvKL9yhYVsC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Zip the runs folder and download it"],"metadata":{"id":"9_seF7xadMzf"}},{"cell_type":"code","source":["!zip -r /content/runs.zip /content/runs\n","\n","from google.colab import files\n","files.download('/content/runs.zip')"],"metadata":{"id":"tZGOiqRrdbZ_"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}